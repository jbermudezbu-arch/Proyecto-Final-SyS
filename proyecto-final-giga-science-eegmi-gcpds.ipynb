{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205,"isSourceIdPinned":false}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto Final Señales y Sistemas 2025 -2\n\n## **Objetivo**: Implementar técnicas de representación en tiempo y frecuencia para el reconocimiento de señales de electroencefalografía (EEG) en tareas de imaginación motora (Motor Imagery)\n\n\n![eegMI](https://figures.semanticscholar.org/288a54f091264377eccc99a19079c9387d66a78f/3-Figure2-1.png)\n\nLas señales de EEG pueden ser ruidosas debido a diversas fuentes, incluidos artefactos fisiológicos e interferencias electromagnéticas. También pueden variar de persona a persona, lo que dificulta la extracción de características y la comprensión de las señales. Además, esta variabilidad, influenciada por factores genéticos y cognitivos, presenta desafíos para el desarrollo de soluciones independientes del sujeto. \n\n**Base de datos**: GiGaScience Database [https://gigadb.org/dataset/100295](https://gigadb.org/dataset/100295)\n\nVer Sección 3.1 en [Multimodal Explainability Using Class Activation Maps and Canonical Correlation for MI-EEG Deep Learning Classification](https://www.mdpi.com/2076-3417/14/23/11208)\n","metadata":{}},{"cell_type":"markdown","source":"## Instalamos las librerias necesarias\n\n## Ejercicio 1\nConsultar para qué sirven las siguientes librerías","metadata":{}},{"cell_type":"code","source":"#!pip install tensorflow==2.15.0\n!pip install mne==1.6.0\n!pip install braindecode===0.7\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:15.878244Z","iopub.execute_input":"2025-12-12T21:30:15.878695Z","iopub.status.idle":"2025-12-12T21:30:43.851516Z","shell.execute_reply.started":"2025-12-12T21:30:15.878655Z","shell.execute_reply":"2025-12-12T21:30:43.850144Z"},"scrolled":true,"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tensorflow:\nPara saber que es tensorflow primero hay que conocer que es un tensor, y la mejor forma de ilustrarlo es por ejemplos: si un escalar (un número solo) es un tensor de orden 0, un vector (dupla, o n-upla) es un tensor de orden 1, una matriz es un tensor de orden 2. Podríamos decir entonces que un tensor es en general un arreglo de números, que puede ser de dimensión n. Así como la recta numérica es la versión de una dimensión del plano cartesiano 2D que a su vez también puede haber plano cartesiano de 3 dimensiones.\nAhora sabiendo que es un tensor, tensorflow es una librería que permite hacer cálculos con tensores, esto es lo que ha permitido y ha impulsado la construcción entrenamiento y despliegue de Redes neuronales artificiales, Transformers y en general las nuevas tecnologías con IA.\n### MNE:\nMNE significa “Magnetoencephalography and Electroencephalography”. Es una librería especializada en el análisis de señales cerebrales como el EEG, es un ecosistema de herramientas para neurociencia, MNE ayuda con la carga y procesamiento de la EEG, su filtrado digital, la extracción de características (como saber que ritmo cerebral tiene una señal), visualización como topografías o mapas de calor.\n### Braindecode: \nLibrería en Python para clasificación, regresión y segmentación de señales EEG usando redes neuronales. Braindecode permite el entrenamiento de modelos de lenguaje, algo como ChatGPT, Braindecode convierte la EEG en tensores listos para entrenar una IA que detecte patrones que no hemos visto antes\n### Python-gcpds.databases:\nEs un paquete de Python que contiene Data loaders, interfaces y acceso fácil a bases de datos EEG usadas por GCPDS, pensado para proyectos de BCI, clasificación de EEG e investigación sobre señales cerebrales.\n","metadata":{}},{"cell_type":"markdown","source":"## Importamos algunas librerias necesarias","metadata":{}},{"cell_type":"code","source":"from scipy.signal import resample\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nimport pandas as pd\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import tensorflow as tf\nfrom gcpds.databases import GIGA_MI_ME\nfrom sklearn.base import BaseEstimator, TransformerMixin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:43.853173Z","iopub.execute_input":"2025-12-12T21:30:43.853613Z","iopub.status.idle":"2025-12-12T21:30:47.514139Z","shell.execute_reply.started":"2025-12-12T21:30:43.853560Z","shell.execute_reply":"2025-12-12T21:30:47.513167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Librerías de Procesamiento de Señales (SciPy.signal)**\n\n```SciPy``` es la librería fundamental de Python para el cálculo científico. El módulo ```scipy.signal``` contiene herramientas esenciales para el procesamiento digital de señales (DSP).\n\n**```scipy.signal.resample```**\n\n*¿Para qué sirve?*\n\nRemuestreo (Resampling): Cambia la frecuencia de muestreo de una señal.Es útil para downsampling (reducir la tasa de muestreo, lo que disminuye el tamaño del archivo) o upsampling (aumentar la tasa de muestreo) para sincronizar señales grabadas con diferentes equipos.\n\n*Uso Típico:*\n\nAjustar los datos EEG de diferentes bases de datos a una frecuencia común (ej., de $1000$ Hz a $250$ Hz) antes de alimentar un modelo de machine learning.\n\n**```scipy.signal.freqz```**\n\n*¿Para qué sirve?*\n\nRespuesta en Frecuencia de un Filtro: Calcula la respuesta en magnitud y fase de un filtro digital (definido por sus coeficientes $b$ y $a$).Permite visualizar y verificar el desempeño de un filtro (por ejemplo, butter que se explica a continuación) antes de aplicarlo a los datos.\n\n*Uso Típico:*\n\nGraficar el espectro de atenuación de un filtro pasabanda para asegurar que solo las frecuencias deseadas pasen a través de él.\n\n**```scipy.signal.filtfilt```**\n\n*¿Para qué sirve?*\n\nFiltrado de Orden Cero (Zero-Phase Filtering): Aplica un filtro digital a los datos dos veces: una vez hacia adelante y una vez hacia atrás.Esto es crucial porque elimina el desplazamiento de fase (retraso) que introduce el filtrado tradicional unidireccional, lo que es vital en el EEG para mantener la alineación temporal de los eventos cerebrales (ERP).\n\n*Uso Típico:*\n\nAplicar un filtro paso alto para eliminar la deriva basal o un filtro de banda eliminada (notch) para suprimir el ruido de la línea eléctrica ($50/60$ Hz) sin distorsionar la forma de onda.\n\n**```scipy.signal.butter as bw```**\n\n*¿Para qué sirve?*\n\nDiseño de Filtros Butterworth: Genera los coeficientes (b y a) necesarios para implementar un filtro Butterworth.Los filtros Butterworth son conocidos por tener la respuesta más plana en la banda de paso (la región de frecuencias que dejan pasar), minimizando la distorsión de la señal útil.\n\n*Uso Típico:*\n\nCrear los coeficientes para un filtro que se aplicará posteriormente con filtfilt. Por ejemplo, para crear un filtro pasabanda entre $0.5$ Hz y $40$ Hz para el análisis EEG.","metadata":{}},{"cell_type":"markdown","source":"\n**Librerías de Ciencia de Datos y Auxiliares**\n\n```pandas (pd)```, ```numpy (np)```, ```random```\n\n**pandas**: La librería esencial para la manipulación y análisis de datos en formato tabular (*DataFrames*). Se usa para gestionar metadatos o la información de los sujetos.\n\n**numpy**: El corazón de la computación numérica en Python. Se usa para manejar *arrays multidimensionales* (matrices), que es la estructura de datos que representa las señales (ej. Canales $\\times$ Puntos de Tiempo).\n\n**random**: Módulo para generar *números aleatorios*. Útil para dividir datos aleatoriamente en conjuntos de entrenamiento y prueba o para inicializar pesos de modelos.\n\n```matplotlib.pyplot as plt```\n\n*¿Para qué sirve?*\n\nVisualización y Gráficos: Es la librería estándar para la creación de gráficos estáticos, interactivos y animaciones en Python.\n\n*Uso Típico*:\n\nGraficar las señales EEG en el dominio del tiempo o del dominio de la frecuencia (ej. la respuesta de freqz).\n\n**Librerías Específicas del Dominio**\n\n```gcpds.databases.GIGA_MI_ME```\n\n¿Para qué sirve?\n\nEsta es la librería del UN-GCPDS que mencionamos anteriormente. Específicamente, parece estar importando una clase o función que facilita el acceso y la descarga de una base de datos específica de EEG: GIGA-MI-ME (probablemente GIGA-Motor Imagery/Motor Execution).\n\nUso Típico:\n\nDescargar o acceder de forma estandarizada a los datos brutos de EEG para el entrenamiento de interfaces cerebro-computadora (BCI) basadas en imaginación motora.\n\n8. sklearn.base.BaseEstimator, TransformerMixin\n¿Para qué sirve?\n\nEstructuración de Código (Scikit-learn): Estos son las clases base que se utilizan en la librería scikit-learn para crear objetos personalizados que se comportan como otros componentes de machine learning (ej. clasificadores, pipelines).\n\nUso Típico:\n\nPermite a los desarrolladores crear sus propias clases de preprocesamiento de datos (ej. una clase llamada MNEToNumpyTransformer que encapsule todo el preprocesamiento MNE) que pueden ser integradas en un pipeline de scikit-learn junto con un clasificador.","metadata":{}},{"cell_type":"markdown","source":"## Funciones necesarias para el preprocesamiento leve de los datos","metadata":{}},{"cell_type":"code","source":"def load_GIGA(db,\n              sbj,\n              eeg_ch_names,\n              new_fs,\n              fs,\n              f_bank=None,\n              vwt=None,           \n              run=None):\n#Cargas el EEG, escoges ciertos canales,\n#tomas solo left/right MI, reorganizas y si quieres cambias la frecuencia de muestreo.\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    #tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    if run == None:\n        X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    else:\n        X, y = db.get_run(run, classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    #X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        pass#print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    return X, y\n\ndef butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n#Aplica un filtro Butterworth pasa-bajas/altas/banda a una señal EEG sin producir desfase.\n  \"\"\"\n  Apply digital butterworth filter\n  INPUT\n  ------\n  1. X: (D array)\n    array with signals.\n  2. N: (int+)\n    The order of the filter.\n  3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n    The type of filter\n  5. fs: (float+)\n    The sampling frequency of the digital system.\n  6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n  8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n  9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n  10. irlen: (int) or None, Default=nONE\n    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n  OUTPUT\n  ------\n  X_fil: (D array)\n    array with filtered signals.\n  \"\"\"\n  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n#toma tu EEG crudo\n\n#lo divide en bandas de frecuencia (con Butterworth)\n\n#lo corta en ventanas temporales\n\n#lo devuelve en forma de tensor 4D o 5D\n\n#listo para meter a una red neuronal\n  \"\"\"\n  Time frequency representation of EEG signals.\n\n  Parameters\n  ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n  Methods\n  -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n  \"\"\"\n  def __init__(self, sfreq, f_bank=None, vwt=None):\n    self.sfreq = sfreq\n    self.f_bank = f_bank\n    self.vwt = vwt\n# ------------------------------------------------------------------------------\n\n  def _validation_param(self):\n    \"\"\"\n    Validate Time-Frequency characterization parameters.\n    INPUT\n    -----\n      1. self\n    ------\n      2. None\n    \"\"\"\n    if self.sfreq <= 0:\n      raise ValueError('Non negative sampling frequency is accepted')\n\n\n    if self.f_bank is None:\n      self.flag_f_bank = False\n    elif self.f_bank.ndim != 2:\n      raise ValueError('Band frequencies have to be a 2D array')\n    else:\n      self.flag_f_bank = True\n\n    if self.vwt is None:\n      self.flag_vwt = False\n    elif self.vwt.ndim != 2:\n      raise ValueError('Time windows have to be a 2D array')\n    else:\n      self.flag_vwt = True\n\n# ------------------------------------------------------------------------------\n  def _filter_bank(self, X):\n    \"\"\"\n    Filter bank Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n    \"\"\"\n    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n    for f in np.arange(self.f_bank.shape[0]):\n      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n    return X_f\n\n# ------------------------------------------------------------------------------\n  def _sliding_windows(self, X):\n    \"\"\"\n    Sliding Windows Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n    \"\"\"\n    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n    for w in np.arange(self.vwt.shape[0]):\n        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n    return X_w\n\n# ------------------------------------------------------------------------------\n  def fit(self, X, y=None):\n    \"\"\"\n    fit.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n      2. y: (1D array) target labels. Default=None\n    OUTPUT\n    ------\n      1. None\n    \"\"\"\n    pass\n\n# ------------------------------------------------------------------------------\n  def transform(self, X, y=None):\n    \"\"\"\n    Time frequency representation of EEG signals.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n    OUTPUT\n    ------\n      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n    \"\"\"\n    self._validation_param()     #Validate sfreq, f_freq, vwt\n\n    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n    if self.flag_f_bank:\n        X_f = self._filter_bank(X)\n    else:\n        X_f = X[:,:,:,np.newaxis]\n\n    if self.flag_vwt:\n      X_wf = []\n      for f in range(X_f.shape[3]):\n        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n      X_wf = np.stack(X_wf, axis=-1)\n    else:\n      X_wf = X_f[:,:,:,np.newaxis,:]\n\n    return X_wf\n\n#plot eeg   \ndef plot_eeg(X,tv,ax,channels,esp=2,title=None):\n    # X in CH x Samples\n    n_canales = X.shape[0]\n\n    for ch in range(n_canales): # canales\n            xx = X[ch]\n            xx = xx - np.mean(xx)\n            xx = xx/np.max(abs(xx))\n            ax.plot(tv, xx +(ch * esp), label=channels[ch])  # Desplazamos cada canal para visualización\n    ax.set_yticks(range(0, esp * n_canales, esp), channels)  # Etiquetas en el eje Y\n    ax.set_xlabel(\"Tiempo [s]\")\n    ax.set_ylabel(\"Canales EEG [$\\mu$V]\")\n    ax.set_title(title)\n    ax.grid(True)\n    ax.set_xlim([min(tv)-0.01,max(tv)+0.01])\n    ax.set_ylim([-esp,n_canales*esp+0.01])\n\n\n\n\n\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:47.516196Z","iopub.execute_input":"2025-12-12T21:30:47.516742Z","iopub.status.idle":"2025-12-12T21:30:47.539115Z","shell.execute_reply.started":"2025-12-12T21:30:47.516713Z","shell.execute_reply":"2025-12-12T21:30:47.537862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Establecemos el protocolo de pruebas y la configuración del montaje EEG\n\nDescribir el protocolo de captura de datos y el montaje utilizado\n\n\n![mi](https://www.mdpi.com/diagnostics/diagnostics-13-01122/article_deploy/html/images/diagnostics-13-01122-g001.png)\n![montaje](https://www.mdpi.com/applsci/applsci-14-11208/article_deploy/html/images/applsci-14-11208-g001.png)","metadata":{}},{"cell_type":"code","source":"channels = ['Fp1','Fpz','Fp2',\n            'AF7','AF3','AFz','AF4','AF8',\n            'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n            'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n            'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n            'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n            'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n            'PO7','PO3','POz','PO4','PO8',\n            'O1','Oz','O2',\n            'Iz']\n\nareas = {\n    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n    #'Central': ['Cz'],\n    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n}\n\narcs = [\n    #'hemispheres',\n    'areas',\n    'channels',\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:47.540902Z","iopub.execute_input":"2025-12-12T21:30:47.541188Z","iopub.status.idle":"2025-12-12T21:30:47.573580Z","shell.execute_reply.started":"2025-12-12T21:30:47.541164Z","shell.execute_reply":"2025-12-12T21:30:47.572642Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Definimos la ruta y los argumentos para la carga de los datos de EEG","metadata":{}},{"cell_type":"code","source":"db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n#ti = 0\n#tf = 7\nnew_fs = 256.\nload_args = dict(db = db,\n                 eeg_ch_names = channels,\n                 fs = db.metadata['sampling_rate'],\n                 #f_bank = np.asarray([[4., 40.]]),\n                 #vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n                 new_fs = new_fs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:47.575062Z","iopub.execute_input":"2025-12-12T21:30:47.575517Z","iopub.status.idle":"2025-12-12T21:30:47.591737Z","shell.execute_reply.started":"2025-12-12T21:30:47.575477Z","shell.execute_reply":"2025-12-12T21:30:47.590687Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cargamos los datos según el sujeto que se quiera","metadata":{}},{"cell_type":"markdown","source":"Si se quiere cargar los datos de todos los sujetos, aplicar un ciclo que itere la lista de sujetos y de esta forma se cargara uno por uno dependiendo lo que se desee realizar.\n\nPor ejemplo:\n\nfor i in sbj:\n    X, y = load_GIGA(sbj=sbj, **load_args)","metadata":{}},{"cell_type":"code","source":"sbj = 5\nX, y = load_GIGA(sbj=sbj, **load_args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:47.592799Z","iopub.execute_input":"2025-12-12T21:30:47.593097Z","iopub.status.idle":"2025-12-12T21:30:53.697899Z","shell.execute_reply.started":"2025-12-12T21:30:47.593066Z","shell.execute_reply":"2025-12-12T21:30:53.696771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'X con {X.shape[0]} intentos; {X.shape[1]} canales; {X.shape[2]} muestras No. de segundos {X.shape[2]/new_fs}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:53.698928Z","iopub.execute_input":"2025-12-12T21:30:53.699300Z","iopub.status.idle":"2025-12-12T21:30:53.705171Z","shell.execute_reply.started":"2025-12-12T21:30:53.699265Z","shell.execute_reply":"2025-12-12T21:30:53.703957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:53.706338Z","iopub.execute_input":"2025-12-12T21:30:53.706687Z","iopub.status.idle":"2025-12-12T21:30:53.725511Z","shell.execute_reply.started":"2025-12-12T21:30:53.706660Z","shell.execute_reply":"2025-12-12T21:30:53.724397Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualización de las señales de EEG en el tiempo","metadata":{}},{"cell_type":"code","source":"#graficar canales promedio\ntrial = 0\nti = 0 # ti\ntf = 7 # tf\ntv = np.arange(ti,tf,1/new_fs)\n\n#Señal cruda\nfig,ax = plt.subplots(1,1,figsize=(8,8),sharex = True)\n# Graficar cada canal en un subplot banda respectiva\n\nplot_eeg(X[trial],tv,ax=ax,channels=channels,title='EEG original')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:53.729324Z","iopub.execute_input":"2025-12-12T21:30:53.729676Z","iopub.status.idle":"2025-12-12T21:30:54.717157Z","shell.execute_reply.started":"2025-12-12T21:30:53.729648Z","shell.execute_reply":"2025-12-12T21:30:54.716083Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 2\n\nDiscuta la gráfica anterior","metadata":{}},{"cell_type":"markdown","source":"### R=/\n\nNuestro compañero Diego nos explico que hay una teoria que dice que los reflejos, o las señales se originan desde el tronco encefalico, o desde la parte trasera del cerebro, y a partir de esto los impulsos se transmiten hacia adelante.\n\nNotando que la organización de las señales detectadas por los electrodos esta justamente siguiendo el patrón antes descrito pudimos visualizar que la gráfica tiene un comportamiento similar a lo descrito por esa teoria, donde los cambios en las señales cerebrales suceden primero en los electrodos de más atras de la cabeza y a partir de ahi hay un leve retardo en las señales de los de mas adelante.\n\nTambién es posible notar que el estimulo se ve reflejado en las señales a partir aproximadamente antes del segundo 3.\n\nParece que el estimulo se mantiene luego de comenzar ya que luego de dicho cambio la señales no vuelven precisamente a su estado original sino que se mantienen con dicho comportamiento.","metadata":{}},{"cell_type":"markdown","source":"Nota: Discuta en qué consisten los ritmos cerebrales\n\n![montaje](https://cdn.shopify.com/s/files/1/0348/7053/files/storage.googleapis.com-486681944373284_61cb9936-f6c2-493d-8402-3426d7f5a049_1024x1024.jpg?v=1689309340)\n\n","metadata":{}},{"cell_type":"markdown","source":"## ¿En que consisten los ritmos cerebrales?\n\nLas neuronas en nuestro cerebro funcionan por medio de pequeñas corrientes electricas, según se ha estudiado dichas corrientes son variantes en el tiempo y tienen oscilasciones como las de una onda sinusoidal sin ser exactamente sinusoidales. Al parecer, la frecuencia de nuestras señales electricas cambia según en que estado mental nos encontramos, a esto es alo que se llama ritmo cerebral, y según estudios se clasifican como:\n\n**Delta:** Sueño profundo (0,5-4 Hz)\n\n**Theta:** creatividad, sueño ligero (4-8 Hz)\n\n**Alpha:** relajación (8-12 Hz)\n\n**Beta:** concentración (13-30 Hz)\n\n**Gamma:** Atención sostenida, integración sensorial, aprendizaje (30-100 Hz)\n\n**High Gamma:** Procesamiento sensorial detallado, actividad durante tareas cognitivas exigentes (80-150 Hz aprox)\n\n**HFO:** Ripples (consolidación de memoria en hipocampo, actividad cercana a la epilepsia 80-250 Hz), Fast Ripples (actividad que genera las crisis de epilepsia 250-500 Hz) y hasta de más de 500 Hz pero solo son visibles en investigación invasiva\n\nDe estas. las últimas 2 no nos interesan para este proyecto, ya que no se suelen estudiar en EEG convencional al ser dificiles de captar con EEG de superficie.\n\n","metadata":{}},{"cell_type":"code","source":"# filtramos trials completos en ritmos cerebrales utilizando filtros IIR\n\n\nf_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]]) # definición del banco de filtros, define las cinco bandas de frecuencia que \n#se suelen estudiar en EEG\nvwt = np.asarray([[ti, tf]]) #2.5 - 5 MI 0 - 7 trial completo #define el segmento temporal del trial que se quiere extraer\ntf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank) #crea un filtro pasa banda por cada banda de EEG, devuelve en forma de tensores 4D o 5D\n\nXrc = np.squeeze(tf_repr.transform(X)) # toma la señal original, se filtra en cada banda definida, se obtiene una representación por banda \n\nXrc.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:54.719144Z","iopub.execute_input":"2025-12-12T21:30:54.719475Z","iopub.status.idle":"2025-12-12T21:30:59.928880Z","shell.execute_reply.started":"2025-12-12T21:30:54.719450Z","shell.execute_reply":"2025-12-12T21:30:59.927487Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 3\n\nExpliqué cómo se calcularon cada una de las 5 dimensiones del arreglo Xrc\n\n### R=/\nTransform es un método al cual se ingresa X el cual tiene la forma:\n\nX.shape = (trials, channels, times)\n\nY fue traido desde la base de datos de EEG con load_GIGA\n\nAhora el método transform filtra por el banco de bandas que ya establecimos antes dando como resultado X_f que tiene la forma:\n\nX_f.shape = (T, C, S, B) donde B es el número de bandas\n\nSe supone que a continuación añade una dimension adicional que corresponde a las ventanas temporales, eso da como resultado:\n\nX_wf.shape = (T, C, S, 1, B) en este caso es 1 por lo que no se usa vwt\n\nAsi finalmente se obtiene que Xrc es:\n\nXrc.shape = (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nritmo = ['delta','theta','alpha','beta','gamma']\ntrial = 0\nn_trials, n_canales, n_muestras, n_bands = Xrc.shape  # Simulación de datos\n\nesp = 2 #espaciado canales\nfig,ax = plt.subplots(5,1,figsize=(8,40))\n# Graficar cada canal en un subplot banda respectiva\nfor b in range(f_bank.shape[0]): #bandas\n    plot_eeg(Xrc[trial,:,:,b],tv,ax=ax[b],channels=channels,title=f'EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:30:59.929886Z","iopub.execute_input":"2025-12-12T21:30:59.930191Z","iopub.status.idle":"2025-12-12T21:31:03.747992Z","shell.execute_reply.started":"2025-12-12T21:30:59.930166Z","shell.execute_reply":"2025-12-12T21:31:03.746856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualización de las señales de EEG en la frecuencia","metadata":{}},{"cell_type":"code","source":"#señal orignal\nXwo = np.fft.rfft(X,axis=-1)\nvfreq = np.fft.rfftfreq(X.shape[2],1/new_fs)\n\nXwo.shape\nplt.plot(vfreq,20*np.log10(np.abs(Xwo[trial])).T)\nplt.xlabel('Frecuencia [Hz]')\nplt.ylabel('Magnitud [dB]')\nplt.title('Eespectro Señal EEG original')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:03.751982Z","iopub.execute_input":"2025-12-12T21:31:03.752424Z","iopub.status.idle":"2025-12-12T21:31:04.291713Z","shell.execute_reply.started":"2025-12-12T21:31:03.752381Z","shell.execute_reply":"2025-12-12T21:31:04.290549Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 4\n\nDiscuta la gráfica anterior\n\n### R=/\n\nLa gráfica muestra el espectro de las señales de EEG que se están estudiando en esta ocasión. Algo que se puede notar a simple vista es un pico en la frecuencia de 60 Hz. Es posible que dicho pico sea ruido producido por la red eléctrica. Esto coincide con lo que se investigo sobre las EEG donde se habla de que es posible ver este ruido en las EEG y por ese motivo se suele aplicar un filtrado a dicha frecuencia.\n\nTambién es posible notar un gran pico apenas al inicio del espectro, esto coincide con las señales que se ven en las ondas filtradas, donde en frecuencias bajas muy al inicio de la prueba hay una oscilación más pronunciada.\n\nEn general el espectro tiene  una magnitud mayor en frecuencias bajas, nuevamente esto es algo que coincide con las gráficas de más arriba que muestran ondas más pronunciadas en el EEG filtrado hasta antes de lo 13 Hz","metadata":{}},{"cell_type":"code","source":"#espectro señales filtradas\nXwb = np.fft.rfft(Xrc,axis=2)\n\nXwb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:04.292835Z","iopub.execute_input":"2025-12-12T21:31:04.293108Z","iopub.status.idle":"2025-12-12T21:31:05.290730Z","shell.execute_reply.started":"2025-12-12T21:31:04.293084Z","shell.execute_reply":"2025-12-12T21:31:05.289696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#espectro señales filtradas por bandas - ritmos cerebrales\n\nfig,ax = plt.subplots(5,1,figsize=(8,40))\n# Graficar cada canal en un subplot banda respectiva\nfor b in range(f_bank.shape[0]): #bandas\n    ax[b].plot(vfreq,20*np.log10(np.abs(Xwb[trial,:,:,b])).T)\n    ax[b].set_xlabel('Frecuencia [Hz]')\n    ax[b].set_ylabel('Magnitud [dB]')\n    ax[b].set_title(f'Esepctro EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:05.291536Z","iopub.execute_input":"2025-12-12T21:31:05.291831Z","iopub.status.idle":"2025-12-12T21:31:07.181379Z","shell.execute_reply.started":"2025-12-12T21:31:05.291806Z","shell.execute_reply":"2025-12-12T21:31:07.179798Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 5\n\nDiscuta las gráficas\n\n### R=/\n\nLas gráficas muestran el comportamiento del filtro en cada una de las bandas seleccionadas. La primera gráfica muestra un filtrado que pasa frecuencias bajas sin apagar por completo lás más altas, esto se visualiza en el pronunciado pico muy al inicio del espectro para su posterior suavidad.\n\nLo mismo pasa en las siguientes gráficas, lo que visualizamos siempre es el comportamiento del filtro pasa bandas, en cada una de las bandas seleccionadas.","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"## Visualización de espectrogramas\n\nConsultar qué es la Short Time Fourier Transform\n\n### R=/\n\nLa Short-Time Fourier Transform (STFT), o Transformada de Fourier de Tiempo Corto, es un método para analizar cómo cambia el contenido en frecuencia de una señal a lo largo del tiempo.\n\nEn términos simples:\n\nTomas la señal continua (por ejemplo, un EEG).\n\nLa divides en ventanas pequeñas (segmentos cortos en el tiempo).\n\nEn cada ventana aplicas la Transformada de Fourier.\n\nObtienes un espectro de frecuencias para cada instante temporal.\n\nEl resultado es una representación tiempo–frecuencia.\n\nLa transformada de Fourier tradicional te dice qué frecuencias hay, pero no cuándo ocurren.\n\nLa STFT te da ambas cosas:\n\nTiempo\n\nFrecuencia\n\n**Como funciona:**\n\nSeleccionas una ventana (por ejemplo, 256 muestras).\n\nTomas ese segmento y aplicas la FFT.\n\nMueves la ventana unos pasos (overlap).\n\nRepites la FFT en cada ventana.\n\nCada ventana produce un espectro de frecuencias:\n\nEl conjunto de todos los espectros forma un espectrograma.\n\n","metadata":{}},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nfrom scipy.signal import stft #\nnperseg = 0.5*new_fs#longitud ventas en muestras\nvfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\nXstft = 20*np.log10(abs(Xstft))\n\n#graficar stft para un trial y un canal\ntrail = 0\nchi = channels.index('C4')\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\n\nax[1].plot(tv,X[trail,chi,:])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Esepctrograma EEG Original -- Ch = {channels[chi]}')\nprint(Xstft.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:07.182772Z","iopub.execute_input":"2025-12-12T21:31:07.183095Z","iopub.status.idle":"2025-12-12T21:31:08.977762Z","shell.execute_reply.started":"2025-12-12T21:31:07.183070Z","shell.execute_reply":"2025-12-12T21:31:08.976769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 2\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:08.978778Z","iopub.execute_input":"2025-12-12T21:31:08.979092Z","iopub.status.idle":"2025-12-12T21:31:15.810924Z","shell.execute_reply.started":"2025-12-12T21:31:08.979067Z","shell.execute_reply":"2025-12-12T21:31:15.809703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 6\n\nPresente las gráficas de stft para distintos canales en los 5 ritmos cerebrales y discuta.","metadata":{}},{"cell_type":"code","source":"nperseg = 0.5*new_fs#longitud ventas en muestras\nvfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\nXstft = 20*np.log10(abs(Xstft))\n\n#graficar stft para un trial y un canal\ntrail = 0\nchi = channels.index('Iz')\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\n\nax[1].plot(tv,X[trail,chi,:])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Original -- Ch = {channels[chi]}')\nprint(Xstft.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:15.812023Z","iopub.execute_input":"2025-12-12T21:31:15.812435Z","iopub.status.idle":"2025-12-12T21:31:17.479957Z","shell.execute_reply.started":"2025-12-12T21:31:15.812396Z","shell.execute_reply":"2025-12-12T21:31:17.478926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 0\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:17.480962Z","iopub.execute_input":"2025-12-12T21:31:17.481235Z","iopub.status.idle":"2025-12-12T21:31:24.127229Z","shell.execute_reply.started":"2025-12-12T21:31:17.481212Z","shell.execute_reply":"2025-12-12T21:31:24.126012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 1\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:32:55.473492Z","iopub.execute_input":"2025-12-12T21:32:55.473878Z","iopub.status.idle":"2025-12-12T21:33:02.135146Z","shell.execute_reply.started":"2025-12-12T21:32:55.473851Z","shell.execute_reply":"2025-12-12T21:33:02.133920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 2\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:33:19.881412Z","iopub.execute_input":"2025-12-12T21:33:19.881834Z","iopub.status.idle":"2025-12-12T21:33:26.451417Z","shell.execute_reply.started":"2025-12-12T21:33:19.881803Z","shell.execute_reply":"2025-12-12T21:33:26.450325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 3\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:33:40.147711Z","iopub.execute_input":"2025-12-12T21:33:40.148060Z","iopub.status.idle":"2025-12-12T21:33:46.701553Z","shell.execute_reply.started":"2025-12-12T21:33:40.148033Z","shell.execute_reply":"2025-12-12T21:33:46.700544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 4\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:33:58.108053Z","iopub.execute_input":"2025-12-12T21:33:58.108497Z","iopub.status.idle":"2025-12-12T21:34:04.672927Z","shell.execute_reply.started":"2025-12-12T21:33:58.108465Z","shell.execute_reply":"2025-12-12T21:34:04.671429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Interpretación:\n\nLas gráficas que estamos viendo en espectro tienen una forma interesante de expresar 3 cosas:\n\nPrimero en el eje X vemos el tiempo\n\nSegundo en el eje Y vemos la frecuencia\n\nY tercero según el color, tal como se ve en la escala de gradiente de color, en cuanto más amarilo significa que hay una mayor magnitud de la frecuencia \n\nEso quiere decir que por ejemplo en la gráfica de el EEG del canal Iz filtrado a ritmo Gamma (32-100 Hz) la magnitud de las frecuencias es mayor entre 32 y un poco más de los 100 Hz (se ve en la colorimetria, ese color amarillo y verde quiere decir más magnitud) Y ademas hay una linea amarillo profundo más arriba del 50, pero debajo del 100, probablemente 60 Hz, tal como habiamos dicho antes quizás producto del ruido de la red eléctrica.\n\nEso mismo sucede en las demás gráficas, nuevamente se ve el comportamiento del filtro, solo que esta vez nos permite percatarnos de en que momento del tiempo hay una cierta frecuencia de manera más o menos intensa en magnitud.\n\nOtro comentario que podemos hacer es respecto al espectrograma de toda la señal (la señal original) donde se ve una mayor magnitud en las frecuencia bajas algo visible por el profundo color amarillo abajo en la gráfica y los colores más oscuros y cercanos al azul en las gráficas de más arriba.\n\nAhora bien, si vemos las gráficas de más arriba que nos permiten visualizar las oscilaciones en distintos canales podemos ver que Iz tiene oscilaciones al principio del intervalo. Para visualizar una señal que tenga oscilaciones distintas y en otro momento del intervalo ahora vamos a visualizar el espectrograma del canal Fp1","metadata":{}},{"cell_type":"code","source":"nperseg = 0.5*new_fs#longitud ventas en muestras\nvfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\nXstft = 20*np.log10(abs(Xstft))\n\n#graficar stft para un trial y un canal\ntrail = 0\nchi = channels.index('Fp1')\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\n\nax[1].plot(tv,X[trail,chi,:])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Original -- Ch = {channels[chi]}')\nprint(Xstft.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:51:27.731388Z","iopub.execute_input":"2025-12-12T21:51:27.733453Z","iopub.status.idle":"2025-12-12T21:51:31.103669Z","shell.execute_reply.started":"2025-12-12T21:51:27.733409Z","shell.execute_reply":"2025-12-12T21:51:31.102441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 0\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:51:59.784437Z","iopub.execute_input":"2025-12-12T21:51:59.784888Z","iopub.status.idle":"2025-12-12T21:52:11.897549Z","shell.execute_reply.started":"2025-12-12T21:51:59.784854Z","shell.execute_reply":"2025-12-12T21:52:11.896241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 1\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:52:34.479649Z","iopub.execute_input":"2025-12-12T21:52:34.480003Z","iopub.status.idle":"2025-12-12T21:52:41.602660Z","shell.execute_reply.started":"2025-12-12T21:52:34.479977Z","shell.execute_reply":"2025-12-12T21:52:41.601476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 2\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:53:06.722545Z","iopub.execute_input":"2025-12-12T21:53:06.722940Z","iopub.status.idle":"2025-12-12T21:53:13.392850Z","shell.execute_reply.started":"2025-12-12T21:53:06.722910Z","shell.execute_reply":"2025-12-12T21:53:13.391629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 3\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:53:28.185706Z","iopub.execute_input":"2025-12-12T21:53:28.186102Z","iopub.status.idle":"2025-12-12T21:53:34.856565Z","shell.execute_reply.started":"2025-12-12T21:53:28.186074Z","shell.execute_reply":"2025-12-12T21:53:34.855388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 4\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Espectrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:53:45.339420Z","iopub.execute_input":"2025-12-12T21:53:45.339845Z","iopub.status.idle":"2025-12-12T21:53:52.233796Z","shell.execute_reply.started":"2025-12-12T21:53:45.339816Z","shell.execute_reply":"2025-12-12T21:53:52.232446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Interpretación de este canal:\n\nAlgo que nos permite ver esta nueva serie de gráficas es que el método que esta usando para el filtrado funciona, y que no estamos mostrando sencillamente gráficas genericas, ya que varia bastante con relación al canal Iz. Al igual que el canal Iz este espectrograma muestra una linea en los 60 Hz debido al ruido de la red electrica y muestra que la mayoria de su espectro esta en frecuencias bajas. Probablemente el sujeto de pruebas se encontraba en relajación a la hora de realizar la toma de muestras y hubieron cambios en sus ritmos cerebrales en  4 momentos en especifico: uno entre 0 y 1 segundos, otro entre 1 y 2 segundos, el tercero entre 2 y 3 segundos y el último hacia el final de la prueba entre 6 y 7 segundos. Por los espectrogramas es posible ver que el cambio de un ritmo cerebral a otro no es instantaneo sino gradual, pues alrededor de donde hay grandes oscilasciones en frecuencias altas es posible ver en los espectrogramas de más arriba oscilaciones en la otras frecuencias pronunciadas.","metadata":{}},{"cell_type":"markdown","source":"## Visualización de señales EEG sobre montaje 10-20","metadata":{}},{"cell_type":"code","source":"import mne\n\n# Cargar el montaje estándar\neasycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n\n\n# Crear un montaje personalizado con los electrodos seleccionados\ncustom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\ncustom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n\n# Mostrar el montaje personalizado\ncustom_montage.plot(show_names=True)\nfig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\nfig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:24.128434Z","iopub.execute_input":"2025-12-12T21:31:24.128947Z","iopub.status.idle":"2025-12-12T21:31:25.029751Z","shell.execute_reply.started":"2025-12-12T21:31:24.128906Z","shell.execute_reply":"2025-12-12T21:31:25.028585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:25.031042Z","iopub.execute_input":"2025-12-12T21:31:25.031456Z","iopub.status.idle":"2025-12-12T21:31:35.128316Z","shell.execute_reply.started":"2025-12-12T21:31:25.031331Z","shell.execute_reply":"2025-12-12T21:31:35.127113Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Topomaps","metadata":{}},{"cell_type":"code","source":"from gcpds.visualizations.topoplots import topoplot\n\n\ntrial = 150\nvec_topo_o = abs(X[trial,:]).mean(axis=-1)\nvec_topo_b = abs(Xrc[trial,:,:,:]).mean(axis=1)\n\n\nfig,ax = plt.subplots(1,6,figsize=(20,10))\ntopoplot(vec_topo_o, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[0],show=False,vlim=(min(vec_topo_o), max(vec_topo_o)))\n\nfor b in range(f_bank.shape[0]):\n    vec_ = vec_topo_b[:,b]\n    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[b+1],show=False,vlim=(min(vec_), max(vec_)))\n    ax[b+1].set_title(ritmo[b])    \n\nax[0].set_title(f'EEG-suj={sbj}-trial={trial}')    \n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:35.130395Z","iopub.execute_input":"2025-12-12T21:31:35.130858Z","iopub.status.idle":"2025-12-12T21:31:36.859138Z","shell.execute_reply.started":"2025-12-12T21:31:35.130816Z","shell.execute_reply":"2025-12-12T21:31:36.857911Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 7\n\nDiscuta\n\n### R=/\n\nPara poder discutir sobre las anteriores gráficas es necesario saber de que se tratan, **¿Que son los Topomaps?**\n\nUn topomap en EEG (topographic map o mapa topográfico) es una representación espacial del voltaje o potencia eléctrica en el cuero cabelludo, mostrada como un mapa de calor sobre una vista 2D de la cabeza.\n\nEn términos sencillos:\nUn topomap te muestra “dónde” en el cerebro o cuero cabelludo está ocurriendo la actividad eléctrica, no solo “cuándo” o “qué frecuencia”.\n\nAhora sabiendo esto, **Discutamos sobre estas graficas:**\n\nEn la primera gráfica se muestra que la mayoria de la actividad se realiza en puntos especificos de la cabeza: entre los sensores F1 y Fz, en el sensor C6T8, en el sensor P10, en AF7, entre C1 y CP1, en C5 y en F6\n\nEn la segunda se ve que la mayoria de actividad delta sucede en C6T8 y en O1.\n\nLa tercera muestra que la gran m,ayoria de actividad Theta sucede al frente de la cabeza, al igual que la actividad Alpha lo que se ve en la cuarta gráfica.\n\nLa quinta muestra que la mayoria de la cabeza tiene buena actividad Beta, pero nuevamente hay un punto de concentración, los sensores C6T8.\n\nPor último la sexta muestra que casi toda la actividad Gamma sucede en C6T8}\n\nA lo largo de las gráficas se nota que entre P1 y POz hay un sitio de muy baja actividad cerebral.\n\nLas gráficas también nos permiten concluir que por algún motivo u otro, para lo que sea que vaya a realizarse con estas EEG resulta muy importante los puntos entre C6T8, ya que es un área de alta actividad.\n\nTeniendo en cuenta esto, creemos que lo que se hizo en esta prueba fue probablemente intentar mover la mano o pierna izquierda del sujeto de pruebas ya que según lo investigado la actividad cerebral es mayor en el lado contrario a la extremidad que se quiere mover.","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"## Common Spatial Patterns\n\nConsulté qué son los Common Spatial Patterns (CSP) y su aplicación al procesado de señales EEG\n\n### R=/\n\n**¿Que son los Common Spatial Patterns? (CSP)**\n\nNormalmente en EEG se tienen muchos canales(electrodos), señales ruidosas y diferencias entre estimulos también llamdos clases muy sutiles, por ejemplo, la diferencia entre las señales de mover la mano derecha y mover la mano izquierda suelen tener diferencias dificiles de ver.\n\nLo que hace el CSP es buscar una cierta combinación de electrodos que separe bien las clases o estimulos.\n\n¿Como separa bien las clases o estimulos? Busca cierta combinación de electrodos donde la varianza (potencia) en una sea grande en un clase y pequeña en la otra.\n\nEs como si el cerebro tocara una orquesta para expresar derecha y una orquesta para expresar izquierda y el CSP se da cuenta de que en la orquesta de izquierda el violin toca mucho más, y es más dominante, mientras que en la orquesta de la derecha el violin casi no varia su melodia y solo hace voces.\n\n**Aplicación al procesado de señales EEG**\n\nSu aplicación número uno es: Extraer características discriminantes para clasificar estados cerebrales a partir de EEG multicanal.\nEs decir que:\nTienes muchas señales mezcladas\n\nCSP encuentra patrones espaciales\n\nEsos patrones convierten el EEG en números separables\n\nEsto se usa en interfaces cerebro computador (BCI) y en clasificación de estados mentales.","metadata":{}},{"cell_type":"code","source":"import mne\nfrom mne.decoding import CSP\n\n# Instancia del objeto CSP\nn_components = 2\ncsp = CSP(n_components=n_components, log= True, transform_into='average_power')\n# Ajuste y transformación de los datos\ncsp_data = csp.fit_transform(X.astype(np.float64), y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:36.860275Z","iopub.execute_input":"2025-12-12T21:31:36.860608Z","iopub.status.idle":"2025-12-12T21:31:40.806226Z","shell.execute_reply.started":"2025-12-12T21:31:36.860582Z","shell.execute_reply":"2025-12-12T21:31:40.804768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"CSP Transformado Shape:\", csp_data.shape)\nplt.scatter(csp_data[:,0],csp_data[:,1],c=y)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:40.807629Z","iopub.execute_input":"2025-12-12T21:31:40.808039Z","iopub.status.idle":"2025-12-12T21:31:40.973734Z","shell.execute_reply.started":"2025-12-12T21:31:40.808003Z","shell.execute_reply":"2025-12-12T21:31:40.972505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#EEG original\nfig,ax = plt.subplots(1,n_components,figsize=(5,5))\nfor cc in range(n_components):\n    vec_ = np.abs(csp.filters_[cc])\n    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[cc],show=False,vlim=(min(vec_), max(vec_)))\n    ax[cc].set_title(f'CSP {cc+1}') \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:40.974785Z","iopub.execute_input":"2025-12-12T21:31:40.975124Z","iopub.status.idle":"2025-12-12T21:31:41.742912Z","shell.execute_reply.started":"2025-12-12T21:31:40.975096Z","shell.execute_reply":"2025-12-12T21:31:41.741684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lectura de datos\nsbj = 14\nX, y = load_GIGA(sbj=sbj, **load_args)\n\nf_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\nvwt = np.array([[0.25, 1.75],[1.5,3],[2.75,4.25],[4,5.5],[5.25,6.75]]) #2.5 - 5 MI 0 - 7 trial completo\ntf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank,vwt=vwt)\nX_ = np.squeeze(tf_repr.transform(X))\nX_.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:41.743887Z","iopub.execute_input":"2025-12-12T21:31:41.744198Z","iopub.status.idle":"2025-12-12T21:31:53.712589Z","shell.execute_reply.started":"2025-12-12T21:31:41.744173Z","shell.execute_reply":"2025-12-12T21:31:53.711446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# csp por ventanas y ritmos\n# Definir las dimensiones del arreglo\nritmos_ = f_bank.shape[0] \nventanas_ = vwt.shape[0]\nn_comp = 2\n# Inicializar el arreglo vacío con listas anidadas\ncsp_M = [[None for _ in range(ventanas_)] for _ in range(ritmos_)]\ncsp_filters_ = np.zeros((ritmos_,ventanas_,X_.shape[1],X_.shape[1])) #ritmos ventanas Ch\nXcsp_ = np.zeros((X_.shape[0],n_comp,ritmos_,ventanas_))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        print(f'CSP ritmo {f_bank[i]} -- ventana {vwt[j]}...')\n        csp_M[i][j] =  CSP(n_components=n_comp, log= True, transform_into='average_power')\n        Xcsp_[:,:,i,j] = csp.fit_transform(X_[:,:,:,j,i].astype(np.float64), y)\n        csp_filters_[i,j,:] = np.abs(csp.filters_) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:31:53.713874Z","iopub.execute_input":"2025-12-12T21:31:53.714256Z","iopub.status.idle":"2025-12-12T21:32:00.991790Z","shell.execute_reply.started":"2025-12-12T21:31:53.714219Z","shell.execute_reply":"2025-12-12T21:32:00.990635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# graficar topomaps\nfig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        vec_ = csp_filters_[i,j,0]\n        vec_ = vec_/max(vec_)\n        topoplot(vec_, channels, contours=3, cmap='Reds', names=None, sensors=False,ax=ax[i,j],show=False,vlim=(min(vec_), max(vec_)))\n    ax[i,0].set_ylabel(ritmo[i],fontsize=20)   \nfor j in range(ventanas_):\n     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n    \nplt.subplots_adjust(hspace=-0.025,wspace=-0.025)    \nplt.show()      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:32:00.996327Z","iopub.execute_input":"2025-12-12T21:32:00.996697Z","iopub.status.idle":"2025-12-12T21:32:04.864902Z","shell.execute_reply.started":"2025-12-12T21:32:00.996669Z","shell.execute_reply":"2025-12-12T21:32:04.863577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#scatters\nfig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        ax[i,j].scatter(Xcsp_[:,0,i,j],Xcsp_[:,1,i,j],c=y)\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])\n    ax[i,0].set_ylabel(ritmo[i],fontsize=20)   \nfor j in range(ventanas_):\n     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n    \nplt.subplots_adjust(hspace=0.1,wspace=0.1)    \nplt.show()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:32:04.866523Z","iopub.execute_input":"2025-12-12T21:32:04.867054Z","iopub.status.idle":"2025-12-12T21:32:06.182954Z","shell.execute_reply.started":"2025-12-12T21:32:04.867009Z","shell.execute_reply":"2025-12-12T21:32:06.181776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}